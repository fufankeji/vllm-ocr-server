#!/usr/bin/env python3
"""
MinerU Service
"""

import asyncio
import json
import logging
import os
import requests
import tempfile
import base64
from io import BytesIO
from pathlib import Path
from typing import Dict, Any, Optional, List
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

# PDFå’Œå›¾åƒå¤„ç†åº“
try:
    import pypdfium2
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    logger.warning("pypdfium2 or PIL not available - image extraction will be disabled")

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = Path(__file__).parent.parent.parent / '.env'
load_dotenv(dotenv_path=env_path, override=True)

class MinerUService:
    """MinerU æœåŠ¡ç±»"""

    def __init__(self):
        # ä½¿ç”¨ ocr_v2_extractors.py ä¸­çš„é…ç½®
        self.api_url = os.getenv("MINERU_API_URL", "http://192.168.110.131:50000/file_parse")
        self.vllm_url = os.getenv("VLLM_SERVER_URL", "http://192.168.110.131:30000")
        self.backend = os.getenv("MINERU_BACKEND", "pipeline")
        self.timeout = int(os.getenv("MINERU_TIMEOUT", "600"))

        # å¯è§†åŒ–è¾“å‡ºç›®å½•
        self.viz_base_dir = Path(os.getenv(
            "MINERU_VIZ_DIR",
            "/home/MuyuWorkSpace/05_OcrProject/backend/mineru_visualizations"
        ))
        self.viz_base_dir.mkdir(parents=True, exist_ok=True)

    async def parse_pdf(
        self,
        pdf_path: str,
        backend: str = "pipeline",
        enable_ocr: bool = True,
        language: str = "ch",
        device: str = "cuda:3"
    ) -> Dict[str, Any]:
        """
        è§£æPDFæ–‡ä»¶ - ä½¿ç”¨ ocr_v2_extractors.py ä¸­çš„ MinerUExtractor é€»è¾‘

        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            backend: åç«¯ç±»å‹
            enable_ocr: æ˜¯å¦å¯ç”¨OCR
            language: æ–‡æ¡£è¯­è¨€
            device: è®¾å¤‡

        Returns:
            è§£æç»“æœå­—å…¸ï¼ŒåŒ…å«markdownå’Œç»“æ„åŒ–æ•°æ®
        """
        try:
            logger.info(f"[MinerU] å¼€å§‹è§£æPDF: {Path(pdf_path).name}")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            pdf_file = Path(pdf_path)
            if not pdf_file.exists():
                return {
                    "success": False,
                    "error": f"PDFæ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}"
                }

            logger.info(f"æ–‡ä»¶: {pdf_file.name}")
            logger.info(f"å¤§å°: {pdf_file.stat().st_size / 1024:.2f} KB")

            # è°ƒç”¨ MinerU API
            logger.info(f"è°ƒç”¨ MinerU API: {self.api_url}")

            # 1. è°ƒç”¨MinerU API
            with open(pdf_file, 'rb') as f:
                files = [('files', (pdf_file.name, f, 'application/pdf'))]
                data = {
                    'backend': backend,
                    'server_url': self.vllm_url,
                    'parse_method': 'auto',
                    'lang_list': language,
                    'return_md': 'true',
                    'return_middle_json': 'true',
                    'return_model_output': 'true',
                    'return_content_list': 'true',
                    'start_page_id': '0',
                    'end_page_id': '99999',
                }

                response = requests.post(
                    self.api_url,
                    files=files,
                    data=data,
                    timeout=self.timeout
                )

            if response.status_code != 200:
                raise Exception(f"MinerU APIè¿”å›é”™è¯¯: {response.status_code}")

            # 2. è§£æè¿”å›ç»“æœï¼ˆå‚è€ƒ ocr_v2_extractors.py:105-125ï¼‰
            if response.headers.get("content-type", "").startswith("application/json"):
                file_json = response.json()
            else:
                file_json = json.loads(response.text)

            # æå–é¡¶å±‚ä¿¡æ¯
            backend = file_json.get("backend", self.backend)
            version = file_json.get("version", "2.5.4")

            # æå–ç»“æœæ•°æ®ï¼ˆæ–‡ä»¶åä½œä¸ºkeyï¼Œå»æ‰.pdfåç¼€ï¼‰
            results = file_json.get("results", {})
            if not results:
                raise Exception("MinerUè¿”å›resultsä¸ºç©º")

            # è·å–ç¬¬ä¸€ä¸ªç»“æœï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªPDFæ–‡ä»¶ï¼‰
            file_key = list(results.keys())[0] if results else None
            if not file_key:
                raise Exception("MinerUè¿”å›ç»“æœä¸ºç©º")

            res = results[file_key]

            # è§£æå„ä¸ªéƒ¨åˆ†ï¼ˆ
            md_content = res.get("md_content", "")

            # è§£æJSONå­—ç¬¦ä¸²
            def safe_json_loads(text):
                if not isinstance(text, str):
                    return text
                try:
                    return json.loads(text.strip())
                except:
                    return None

            middle_json = safe_json_loads(res.get("middle_json"))
            model_output = safe_json_loads(res.get("model_output"))
            content_list = safe_json_loads(res.get("content_list"))

            # è°ƒè¯• images æ•°æ®
            images_raw = res.get("images")
            logger.info(f"images_raw type: {type(images_raw)}")
            if images_raw:
                logger.info(f"images_raw preview: {str(images_raw)[:200]}...")
            else:
                logger.warning("APIè¿”å›çš„images_rawä¸ºNoneæˆ–ç©º - è¿™æ˜¯æ­£å¸¸çš„,50000ç«¯å£APIä¸è¿”å›images")

            images = safe_json_loads(images_raw)
            logger.info(f"images after safe_json_loads type: {type(images)}")
            if images:
                if isinstance(images, dict):
                    logger.info(f"images keys: {list(images.keys())[:3]}")
                else:
                    logger.info(f"images is not dict: {type(images)}")
            else:
                # 50000ç«¯å£APIä¸è¿”å›images,éœ€è¦ä»PDFä¸­æå–å›¾ç‰‡
                logger.info("ä»PDFæå–å›¾ç‰‡æ•°æ®")
                images = self._extract_images_from_pdf(pdf_file, content_list, middle_json)
                logger.info(f"æå–äº† {len(images)} ä¸ªå›¾ç‰‡")

            page_images = safe_json_loads(res.get("page_images"))

            # ç»Ÿè®¡ä¿¡æ¯
            total_pages = len(middle_json.get("pdf_info", [])) if middle_json else 0
            total_images = self._count_images(middle_json)

            logger.info("è§£æå®Œæˆï¼")
            logger.info(f"   - Markdown é•¿åº¦: {len(md_content)} å­—ç¬¦")
            logger.info(f"   - æ€»é¡µæ•°: {total_pages}")
            logger.info(f"   - å›¾ç‰‡æ•°é‡: {total_images}")
            logger.info(f"   - Content_list æ¡ç›®: {len(content_list) if content_list else 0}")

            # 3. ä¿å­˜ç»“æœåˆ°æœ¬åœ°ï¼ˆä¿æŒä¸åŸæ¥ç›¸åŒçš„é€»è¾‘ï¼‰
            output_dir = Path(os.getenv("TEMP_DIR", "./temp"))
            output_dir.mkdir(parents=True, exist_ok=True)

            output_file = output_dir / f"{pdf_file.stem}_parsed.md"
            output_file.write_text(md_content, encoding='utf-8')

            logger.info(f"Markdownå·²ä¿å­˜åˆ°: {output_file.absolute()}")

            # 4. è¿”å›å®Œæ•´ç»“æœï¼ˆåŒ…å«ç»“æ„åŒ–æ•°æ®ï¼‰
            return {
                "success": True,
                "content": md_content,
                "markdown_file": str(output_file),
                "raw_data": {
                    # ä¿ç•™åŸå§‹ API è¿”å›çš„æ‰€æœ‰å­—æ®µï¼ˆå‚è€ƒ ocr_v2_extractors.py:180-202ï¼‰
                    'md_content': md_content,
                    'middle_json': middle_json,  # å·²è§£æçš„å¯¹è±¡ï¼ˆä¸æ˜¯å­—ç¬¦ä¸²ï¼‰
                    'model_output': model_output,  # å·²è§£æçš„å¯¹è±¡
                    'content_list': content_list,  # å·²è§£æçš„å¯¹è±¡
                    'images': images,  # å›¾ç‰‡æ•°æ®
                    'page_images': page_images,  # é¡µé¢å›¾ç‰‡æ•°æ®
                    # æ·»åŠ é¡¶å±‚ä¿¡æ¯
                    'backend': backend,
                    'version': version,
                },
                "metadata": {
                    "backend": backend,
                    "version": version,
                    "total_pages": total_pages,
                    "total_images": total_images,
                    "content_list_count": len(content_list) if content_list else 0
                },
                "stats": {
                    "totalCharacters": len(md_content),
                    "totalLines": md_content.count(chr(10)) + 1,
                    "fileSizeKB": output_file.stat().st_size / 1024
                }
            }

        except Exception as e:
            logger.error(f"[MinerU] è§£æPDFå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": f"MinerUè§£æå¤±è´¥: {str(e)}"
            }

    def _count_images(self, middle_json: dict) -> int:
        """ç»Ÿè®¡å›¾ç‰‡æ•°é‡ï¼ˆå‚è€ƒ ocr_v2_extractors.py:210-221ï¼‰"""
        if not middle_json:
            return 0

        count = 0
        pdf_info = middle_json.get("pdf_info", [])
        for page in pdf_info:
            for block in page.get("preproc_blocks", []):
                if block.get("type") == "image":
                    count += 1
        return count

    def _calculate_transform_params(
        self,
        page_idx: int,
        middle_json: dict,
        content_list: list
    ) -> tuple:
        """è®¡ç®—åæ ‡è½¬æ¢å‚æ•°ï¼ˆæ¥è‡ªå‚è€ƒä»£ç ï¼‰"""
        SCALE_X = SCALE_Y = 1.0
        OFFSET_X = OFFSET_Y = 0.0

        if not middle_json:
            return (SCALE_X, SCALE_Y, OFFSET_X, OFFSET_Y)

        pdf_info = middle_json.get("pdf_info", [])
        if page_idx >= len(pdf_info):
            return (SCALE_X, SCALE_Y, OFFSET_X, OFFSET_Y)

        middle_blocks = pdf_info[page_idx].get("preproc_blocks", [])
        content_items = [
            item for item in content_list
            if isinstance(item, dict) and item.get("page_idx") == page_idx
        ]

        if middle_blocks and content_items:
            m_bbox = middle_blocks[0].get("bbox", [])
            c_bbox = content_items[0].get("bbox", [])

            if len(m_bbox) >= 4 and len(c_bbox) >= 4:
                SCALE_X = (c_bbox[2] - c_bbox[0]) / (m_bbox[2] - m_bbox[0]) if (m_bbox[2] - m_bbox[0]) > 0 else 1.0
                SCALE_Y = (c_bbox[3] - c_bbox[1]) / (m_bbox[3] - m_bbox[1]) if (m_bbox[3] - m_bbox[1]) > 0 else 1.0
                OFFSET_X = c_bbox[0] - m_bbox[0] * SCALE_X
                OFFSET_Y = c_bbox[1] - m_bbox[1] * SCALE_Y

        return (SCALE_X, SCALE_Y, OFFSET_X, OFFSET_Y)

    def _transform_bbox(
        self,
        bbox: list,
        page_idx: int,
        middle_json: dict,
        content_list: list,
        W_img: int,
        H_img: int,
        W_pdf: float,
        H_pdf: float
    ) -> list:
        """è½¬æ¢ bbox åæ ‡ï¼ˆæ¥è‡ªå‚è€ƒä»£ç ï¼‰"""
        # è·å–è½¬æ¢å‚æ•°
        SCALE_X, SCALE_Y, OFFSET_X, OFFSET_Y = self._calculate_transform_params(
            page_idx, middle_json, content_list
        )

        # 1. å»é™¤åç§»
        bbox_no_offset = [
            bbox[0] - OFFSET_X,
            bbox[1] - OFFSET_Y,
            bbox[2] - OFFSET_X,
            bbox[3] - OFFSET_Y
        ]

        # 2. åç¼©æ”¾åˆ° PDF åæ ‡ç³»
        bbox_in_pdf = [
            bbox_no_offset[0] / SCALE_X if SCALE_X != 0 else bbox_no_offset[0],
            bbox_no_offset[1] / SCALE_Y if SCALE_Y != 0 else bbox_no_offset[1],
            bbox_no_offset[2] / SCALE_X if SCALE_X != 0 else bbox_no_offset[2],
            bbox_no_offset[3] / SCALE_Y if SCALE_Y != 0 else bbox_no_offset[3]
        ]

        # 3. ç¼©æ”¾åˆ°å›¾ç‰‡åæ ‡ç³»
        sx = W_img / W_pdf if W_pdf > 0 else 1.0
        sy = H_img / H_pdf if H_pdf > 0 else 1.0
        final_bbox = [
            bbox_in_pdf[0] * sx,
            bbox_in_pdf[1] * sy,
            bbox_in_pdf[2] * sx,
            bbox_in_pdf[3] * sy
        ]

        return final_bbox

    def _extract_images_from_pdf(
        self,
        pdf_path: Path,
        content_list: list,
        middle_json: dict
    ) -> dict:
        """ä»PDFä¸­æå–å›¾ç‰‡å¹¶ç¼–ç ä¸ºbase64"""
        if not PIL_AVAILABLE or not content_list:
            logger.warning("PIL or pypdfium2 not available, cannot extract images")
            return {}

        try:
            images_dict = {}

            # æ‰“å¼€PDFæ–‡æ¡£
            doc = pypdfium2.PdfDocument(str(pdf_path))
            logger.info(f"ğŸ“– æ‰“å¼€PDFæ–‡æ¡£ï¼Œå…± {len(doc)} é¡µ")

            # åˆ›å»ºé¡µé¢å›¾ç‰‡ç¼“å­˜
            page_images_cache = {}

            # éå†content_listä¸­çš„å›¾ç‰‡
            for item in content_list:
                if not isinstance(item, dict):
                    continue

                item_type = item.get("type", "")
                if item_type != "image":
                    continue

                img_path = item.get("img_path", "")
                bbox = item.get("bbox", [])
                page_idx = item.get("page_idx", 0)

                if not img_path or len(bbox) < 4:
                    continue

                try:
                    # æ¸²æŸ“é¡µé¢å›¾ç‰‡ï¼ˆå¦‚æœè¿˜æ²¡æ¸²æŸ“ï¼‰
                    if page_idx not in page_images_cache:
                        if page_idx >= len(doc):
                            logger.warning(f"âš ï¸  é¡µé¢ç´¢å¼• {page_idx} è¶…å‡ºèŒƒå›´")
                            continue

                        page = doc.get_page(page_idx)
                        pil_img = page.render(scale=2.0).to_pil()  # ä½¿ç”¨2.0ç¼©æ”¾ä»¥è·å¾—æ›´å¥½è´¨é‡
                        page_images_cache[page_idx] = pil_img
                        logger.info(f"ğŸ“„ æ¸²æŸ“é¡µé¢ {page_idx}, å°ºå¯¸: {pil_img.size}")

                    page_img = page_images_cache[page_idx]
                    W_img, H_img = page_img.size

                    # è·å–PDFé¡µé¢å°ºå¯¸
                    pdf_info = middle_json.get("pdf_info", [])
                    if page_idx < len(pdf_info):
                        page_info = pdf_info[page_idx]
                        W_pdf = page_info.get("width", 595)
                        H_pdf = page_info.get("height", 841)
                    else:
                        W_pdf, H_pdf = 595, 841

                    # ä½¿ç”¨å‚è€ƒä»£ç çš„åæ ‡è½¬æ¢é€»è¾‘
                    final_bbox = self._transform_bbox(
                        bbox, page_idx, middle_json, content_list, W_img, H_img, W_pdf, H_pdf
                    )

                    # è½¬æ¢ä¸ºæ•´æ•°åæ ‡å¹¶è£åˆ‡
                    x1 = max(0, int(round(final_bbox[0])))
                    y1 = max(0, int(round(final_bbox[1])))
                    x2 = min(W_img, int(round(final_bbox[2])))
                    y2 = min(H_img, int(round(final_bbox[3])))

                    if x2 <= x1 or y2 <= y1:
                        logger.warning(f"âš ï¸  æ— æ•ˆçš„bbox: {bbox}")
                        continue

                    # è£å‰ªå›¾ç‰‡
                    cropped = page_img.crop((x1, y1, x2, y2))

                    # è‡ªåŠ¨è£å‰ªç™½è¾¹
                    try:
                        # è½¬æ¢ä¸ºRGBæ¨¡å¼ä»¥ä¾¿å¤„ç†
                        if cropped.mode != 'RGB':
                            cropped = cropped.convert('RGB')

                        # ä½¿ç”¨getbbox()è‡ªåŠ¨æ£€æµ‹éç™½è‰²åŒºåŸŸ
                        # å…ˆè½¬æ¢ä¸ºç°åº¦å›¾ï¼Œç„¶ååè½¬ï¼ˆè®©ç™½è‰²å˜æˆé»‘è‰²ï¼‰
                        import numpy as np
                        img_array = np.array(cropped)

                        # è®¡ç®—æ¯ä¸ªåƒç´ çš„äº®åº¦
                        gray = np.mean(img_array, axis=2)

                        # æ‰¾åˆ°éç™½è‰²åŒºåŸŸï¼ˆé˜ˆå€¼240ï¼Œæ¥è¿‘ç™½è‰²çš„ä¹Ÿç®—ç™½è‰²ï¼‰
                        mask = gray < 240

                        # è·å–éç™½è‰²åŒºåŸŸçš„è¾¹ç•Œ
                        rows = np.any(mask, axis=1)
                        cols = np.any(mask, axis=0)

                        if rows.any() and cols.any():
                            rmin, rmax = np.where(rows)[0][[0, -1]]
                            cmin, cmax = np.where(cols)[0][[0, -1]]

                            # è£å‰ªæ‰ç™½è¾¹ï¼Œä¿ç•™2åƒç´ çš„è¾¹è·
                            margin = 2
                            rmin = max(0, rmin - margin)
                            cmin = max(0, cmin - margin)
                            rmax = min(cropped.height - 1, rmax + margin)
                            cmax = min(cropped.width - 1, cmax + margin)

                            cropped = cropped.crop((cmin, rmin, cmax + 1, rmax + 1))
                    except Exception as e:
                        logger.warning(f"âš ï¸  è‡ªåŠ¨è£å‰ªç™½è¾¹å¤±è´¥: {str(e)}")
                        # å¦‚æœå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è£å‰ªçš„å›¾ç‰‡

                    # è½¬æ¢ä¸ºbase64
                    buffered = BytesIO()
                    cropped.save(buffered, format="PNG")
                    img_base64 = f"data:image/png;base64,{base64.b64encode(buffered.getvalue()).decode('utf-8')}"

                    images_dict[img_path] = img_base64
                    logger.info(f"âœ… æå–å›¾ç‰‡: {img_path}, å°ºå¯¸: {x2-x1}x{y2-y1}")

                except Exception as e:
                    logger.error(f"âŒ æå–å›¾ç‰‡å¤±è´¥ {img_path}: {str(e)}")

            doc.close()
            return images_dict

        except Exception as e:
            logger.error(f"âŒ PDFå›¾ç‰‡æå–å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return {}

    async def check_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥MinerU APIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.api_url.replace('/file_parse', '/health')}", timeout=5)
            if response.status_code == 200:
                return {
                    "available": True,
                    "url": self.api_url,
                    "status": response.status_code,
                    "response": response.json()
                }
            else:
                return {
                    "available": False,
                    "url": self.api_url,
                    "status": response.status_code,
                    "error": f"HTTP {response.status_code}"
                }
        except Exception as e:
            return {
                "available": False,
                "url": self.api_url,
                "error": str(e)
            }

    async def get_available_tools(self) -> Dict[str, Any]:
        """è·å–MinerU APIæä¾›çš„åŠŸèƒ½ä¿¡æ¯"""
        try:
            logger.info(f"ğŸ”Œ æ£€æŸ¥ MinerU API: {self.api_url}")

            # å°è¯•ç®€å•çš„å¥åº·æ£€æŸ¥
            response = requests.get(f"{self.api_url.replace('/file_parse', '/health')}", timeout=5)

            if response.status_code == 200:
                logger.info("âœ… MinerU API æœåŠ¡å¯ç”¨")
                return {
                    "success": True,
                    "tools": [
                        {
                            "name": "file_parse",
                            "description": "MinerUæ–‡æ¡£è§£æAPI",
                            "parameters": {
                                "file": "PDFæ–‡ä»¶",
                                "backend": "å¤„ç†åç«¯ç±»å‹",
                                "return_md": "è¿”å›markdown",
                                "return_middle_json": "è¿”å›ä¸­é—´JSON",
                                "return_content_list": "è¿”å›å†…å®¹åˆ—è¡¨"
                            }
                        }
                    ],
                    "count": 1
                }
            else:
                logger.warning(f"âš ï¸ MinerU API å“åº”å¼‚å¸¸: {response.status_code}")
                return {
                    "success": False,
                    "error": f"APIå“åº”å¼‚å¸¸: HTTP {response.status_code}"
                }

        except Exception as e:
            logger.error(f"âŒ MinerU API è¿æ¥å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": f"è¿æ¥MinerU APIå¤±è´¥: {str(e)}"
            }