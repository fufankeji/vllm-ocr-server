"""
PaddleOCR-VL æœåŠ¡å°è£…
å¤„ç† PDF å’Œå›¾ç‰‡æ–‡ä»¶çš„ OCR è¯†åˆ«
"""

import base64
import json
import logging
import os
import requests
from pathlib import Path
from typing import Dict, List, Optional
import re

logger = logging.getLogger(__name__)


class PaddleOCRService:
    """PaddleOCR-VL OCR æœåŠ¡"""

    def __init__(self):
        """
        åˆå§‹åŒ– PaddleOCR æœåŠ¡
        """
        self.api_url = os.getenv("PADDLEOCR_API_URL", "http://192.168.110.131:10800/layout-parsing")
        logger.info(f"ğŸ”§ Initialized PaddleOCR service with API: {self.api_url}")

    async def process_file(self, file_path: str) -> Dict:
        """
        å¤„ç†æ–‡ä»¶ï¼ˆPDF æˆ–å›¾ç‰‡ï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            åŒ…å« markdownã€imagesã€tablesã€formulas çš„ç»“æœå­—å…¸
        """
        try:
            logger.info(f"Processing file with PaddleOCR: {file_path}")

            # è¯»å–æ–‡ä»¶å¹¶ç¼–ç ä¸º base64
            with open(file_path, "rb") as f:
                file_base64 = base64.b64encode(f.read()).decode("utf-8")

            # åˆ¤æ–­æ–‡ä»¶ç±»å‹
            file_extension = Path(file_path).suffix.lower()
            if file_extension == ".pdf":
                file_type = 0  # PDF
            elif file_extension in [".png", ".jpg", ".jpeg", ".bmp"]:
                file_type = 1  # å›¾ç‰‡
            else:
                logger.warning(f"âš ï¸  Unknown file type: {file_extension}, treating as image")
                file_type = 1

            # æ„é€ è¯·æ±‚
            payload = {
                "file": file_base64,
                "fileType": file_type,
                "prettifyMarkdown": True,
                "visualize": False,
            }

            headers = {"Content-Type": "application/json"}

            # å‘é€è¯·æ±‚
            logger.info("Sending request to PaddleOCR API...")
            response = requests.post(
                self.api_url,
                headers=headers,
                data=json.dumps(payload),
                timeout=300
            )

            if response.status_code != 200:
                error_msg = f"PaddleOCR API error: {response.status_code}"
                logger.error(f"{error_msg}")
                logger.error(f"Response: {response.text[:500]}")
                raise Exception(error_msg)

            # è§£æå“åº”
            result = response.json()

            # æ£€æŸ¥é”™è¯¯ç 
            error_code = result.get("errorCode")
            if error_code != 0:
                error_msg = result.get("errorMsg", "Unknown error")
                logger.error(f"PaddleOCR service error (code: {error_code}): {error_msg}")
                raise Exception(f"PaddleOCR error: {error_msg}")

            logger.info("âœ… PaddleOCR API response received")

            # æå–å’Œå¤„ç†ç»“æœ
            processed_result = self._process_response(result, file_path)

            return processed_result

        except Exception as e:
            logger.error(f"PaddleOCR processing failed: {e}")
            raise

    def _process_response(self, api_response: Dict, file_path: str) -> Dict:
        """
        å¤„ç† PaddleOCR API å“åº”

        Args:
            api_response: API åŸå§‹å“åº”
            file_path: åŸå§‹æ–‡ä»¶è·¯å¾„

        Returns:
            æ ‡å‡†åŒ–çš„ç»“æœå­—å…¸
        """
        logger.info("Processing PaddleOCR response...")

        result_data = api_response.get("result", {})
        layout_parsing_results = result_data.get("layoutParsingResults", [])

        # åˆå§‹åŒ–ç»“æœ
        results = {
            "markdown": "",
            "images": [],
            "tables": [],
            "formulas": [],
            "metadata": {
                "total_pages": len(layout_parsing_results),
                "file_name": Path(file_path).name,
            }
        }

        # æ”¶é›†æ‰€æœ‰é¡µé¢çš„å†…å®¹
        all_markdown_parts = []

        for page_idx, page_result in enumerate(layout_parsing_results):
            logger.info(f"Processing page {page_idx + 1}...")

            # æå– markdown
            markdown_data = page_result.get("markdown", {})
            markdown_text = markdown_data.get("text", "")
            # æ³¨æ„ï¼šå­—æ®µåæ˜¯ "images" ä¸æ˜¯ "markdownImages"
            markdown_images = markdown_data.get("images", {})

            # æ·»åŠ é¡µé¢æ ‡è®°
            all_markdown_parts.append(f"\n\n# Page {page_idx + 1}\n\n")
            all_markdown_parts.append(markdown_text)

            # ä» markdown_images å­—å…¸æå–å›¾ç‰‡
            if markdown_images:
                logger.info(f"   Found {len(markdown_images)} images in markdown.images")
                for img_filename, img_base64 in markdown_images.items():
                    # æ„å»º data URI
                    # åˆ¤æ–­å›¾ç‰‡æ ¼å¼
                    if img_filename.endswith('.jpg') or img_filename.endswith('.jpeg'):
                        data_uri = f"data:image/jpeg;base64,{img_base64}"
                    elif img_filename.endswith('.png'):
                        data_uri = f"data:image/png;base64,{img_base64}"
                    else:
                        data_uri = f"data:image/jpeg;base64,{img_base64}"  # é»˜è®¤ jpeg

                    image_info = {
                        "id": f"page_{page_idx}_{img_filename.replace('.jpg', '').replace('.png', '')}",
                        "type": "å›¾ç‰‡",
                        "description": f"Page {page_idx + 1} - {img_filename}",
                        "altText": img_filename,
                        "confidence": 95.0,
                        "base64": data_uri,
                        "path": img_filename,
                        "page": page_idx
                    }
                    results["images"].append(image_info)

            # ä» markdown æ–‡æœ¬ä¸­æå– HTML è¡¨æ ¼
            tables_in_page = self._extract_tables_from_markdown(markdown_text, page_idx)
            results["tables"].extend(tables_in_page)

        # åˆå¹¶æ‰€æœ‰é¡µé¢çš„ markdown
        results["markdown"] = "".join(all_markdown_parts)

        logger.info(f"âœ… Extracted: {len(results['images'])} images, "
                   f"{len(results['tables'])} tables, "
                   f"{len(results['formulas'])} formulas")

        return results

    def _extract_image_from_region(
        self,
        region: Dict,
        page_idx: int,
        markdown_images: Dict
    ) -> Optional[Dict]:
        """ä» region ä¸­æå–å›¾ç‰‡ä¿¡æ¯"""
        try:
            # è·å–å›¾ç‰‡çš„ bbox
            bbox = region.get("bbox", [])
            if len(bbox) < 4:
                return None

            # æŸ¥æ‰¾å¯¹åº”çš„ base64 å›¾ç‰‡æ•°æ®
            # markdown ä¸­çš„å›¾ç‰‡è·¯å¾„æ ¼å¼: imgs/img_in_image_box_x1_y1_x2_y2.jpg
            image_filename = None
            image_base64 = None

            # ä» markdownImages ä¸­æŸ¥æ‰¾åŒ¹é…çš„å›¾ç‰‡
            for img_name, img_data in markdown_images.items():
                if f"_{int(bbox[0])}_{int(bbox[1])}_" in img_name:
                    image_filename = img_name
                    image_base64 = img_data
                    break

            if not image_base64:
                logger.warning(f"No base64 data found for image at bbox {bbox}")
                return None

            # æ„å»º data URI
            data_uri = f"data:image/jpeg;base64,{image_base64}"

            return {
                "id": f"page_{page_idx}_img_{int(bbox[0])}_{int(bbox[1])}",
                "type": region.get("type", "å›¾ç‰‡"),
                "description": f"Page {page_idx + 1} - {region.get('type', 'Image')}",
                "altText": image_filename or f"Image on page {page_idx + 1}",
                "confidence": 95.0,
                "base64": data_uri,
                "path": image_filename,
                "bbox": bbox,
                "page": page_idx
            }

        except Exception as e:
            logger.warning(f"Failed to extract image from region: {e}")
            return None

    def _extract_table_from_region(
        self,
        region: Dict,
        page_idx: int
    ) -> Optional[Dict]:
        """ä» region ä¸­æå–è¡¨æ ¼ä¿¡æ¯"""
        try:
            # è·å–è¡¨æ ¼çš„ HTML å†…å®¹
            table_result = region.get("tableResult", {})
            table_html = table_result.get("html", "")

            if not table_html:
                logger.warning("No HTML content in table region")
                return None

            # è§£æ HTML è¡¨æ ¼ä¸ºç»“æ„åŒ–æ•°æ®
            headers, rows = self._parse_html_table(table_html)

            if not headers or not rows:
                return None

            bbox = region.get("bbox", [])

            return {
                "id": f"page_{page_idx}_table_{int(bbox[0]) if bbox else 0}",
                "title": f"è¡¨æ ¼ (Page {page_idx + 1})",
                "headers": headers,
                "rows": rows,
                "rowCount": len(rows),
                "columnCount": len(headers),
                "confidence": 95.0,
                "html": table_html,
                "bbox": bbox,
                "page": page_idx
            }

        except Exception as e:
            logger.warning(f"Failed to extract table from region: {e}")
            return None

    def _extract_formula_from_region(
        self,
        region: Dict,
        page_idx: int
    ) -> Optional[Dict]:
        """ä» region ä¸­æå–å…¬å¼ä¿¡æ¯"""
        try:
            # è·å–å…¬å¼çš„ LaTeX å†…å®¹
            formula_result = region.get("formulaResult", {})
            latex = formula_result.get("latex", "")

            if not latex:
                # å°è¯•ä» text å­—æ®µè·å–
                latex = region.get("text", "")

            if not latex:
                return None

            bbox = region.get("bbox", [])

            return {
                "id": f"page_{page_idx}_formula_{int(bbox[0]) if bbox else 0}",
                "latex": latex,
                "type": region.get("type", "formula"),
                "bbox": bbox,
                "page": page_idx,
                "confidence": 90.0
            }

        except Exception as e:
            logger.warning(f"Failed to extract formula from region: {e}")
            return None

    def _extract_tables_from_markdown(self, markdown_text: str, page_idx: int) -> list:
        """ä» markdown æ–‡æœ¬ä¸­æå– HTML è¡¨æ ¼"""
        tables = []
        table_pattern = r'<table[^>]*>(.*?)</table>'
        matches = re.findall(table_pattern, markdown_text, re.DOTALL | re.IGNORECASE)

        logger.info(f"   Found {len(matches)} HTML tables in markdown")

        for table_idx, table_html in enumerate(matches):
            try:
                headers, rows = self._parse_html_table(f"<table>{table_html}</table>")

                if headers and rows:
                    table_info = {
                        "id": f"page_{page_idx}_table_{table_idx}",
                        "title": f"è¡¨æ ¼ {table_idx + 1} (Page {page_idx + 1})",
                        "headers": headers,
                        "rows": rows,
                        "rowCount": len(rows),
                        "columnCount": len(headers),
                        "confidence": 95.0,
                        "html": f"<table>{table_html}</table>",
                        "page": page_idx
                    }
                    tables.append(table_info)
            except Exception as e:
                logger.warning(f"Failed to parse table {table_idx} on page {page_idx}: {e}")

        return tables

    def _parse_html_table(self, table_html: str) -> tuple:
        """
        è§£æ HTML è¡¨æ ¼

        Returns:
            (headers, rows) å…ƒç»„
        """
        try:
            # æå–æ‰€æœ‰è¡Œ
            row_pattern = r'<tr[^>]*>(.*?)</tr>'
            rows_html = re.findall(row_pattern, table_html, re.DOTALL | re.IGNORECASE)

            headers = []
            data_rows = []

            for row_idx, row_html in enumerate(rows_html):
                # æå–å•å…ƒæ ¼ï¼ˆåŒ…æ‹¬ th å’Œ tdï¼‰
                cell_pattern = r'<t[dh][^>]*>(.*?)</t[dh]>'
                cells = re.findall(cell_pattern, row_html, re.DOTALL | re.IGNORECASE)

                # æ¸…ç† HTML æ ‡ç­¾
                cells = [re.sub(r'<[^>]+>', '', cell).strip() for cell in cells]

                if row_idx == 0:
                    # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
                    headers = cells
                else:
                    # å…¶ä»–è¡Œä½œä¸ºæ•°æ®
                    data_rows.append(cells)

            return headers, data_rows

        except Exception as e:
            logger.warning(f"Failed to parse HTML table: {e}")
            return [], []


# å…¨å±€æœåŠ¡å®ä¾‹
paddleocr_service = PaddleOCRService()
